import os
from easydict import EasyDict as edict
import time
import torch

# init
__C = edict()
cfg = __C

#------------------------------TRAIN------------------------
__C.SEED = 3035 # random seed,  for reporduction
__C.DATASET = 'UCF50' # dataset selection: GCC, SHHA, SHHB, UCF50, QNRF, WE

if __C.DATASET == 'UCF50':# only for UCF50
	from datasets.UCF50.setting import cfg_data
	__C.VAL_INDEX = cfg_data.VAL_INDEX 

if __C.DATASET == 'GCC':# only for GCC
	from datasets.GCC.setting import cfg_data
	__C.VAL_MODE = cfg_data.VAL_MODE 


__C.NET = 'Res101_FPN' # net selection: MCNN, AlexNet, VGG, VGG_DECODER, Res50, CSRNet, SANet, Res50_FPN

__C.PRE_GCC = False # use the pretrained model on GCC dataset
__C.PRE_GCC_MODEL = '' # path to model

__C.GPU_ID = [0] # sigle gpu: [0], [1] ...; multi gpus: [0,1]

# learning rate settings
__C.LR = 1e-5 # learning rate
__C.LR_DECAY = 0.995 # decay rate
__C.LR_DECAY_START = -1 # when training epoch is more than it, the learning rate will be begin to decay
__C.NUM_EPOCH_LR_DECAY = 1 # decay frequency
__C.MAX_EPOCH = 100

# multi-task learning weights, no use for single model, such as MCNN, VGG, VGG_DECODER, Res50, CSRNet, and so on

__C.LAMBDA_1 = 1e-3# SANet:0.001 CMTL 0.0001


# print 
__C.PRINT_FREQ = 2

now = time.strftime("%m-%d_%H-%M", time.localtime())

__C.EXP_NAME = now \
			 + '_' + __C.DATASET \
             + '_' + __C.NET \
             + '_' + str(__C.LR)

if __C.DATASET == 'UCF50':
	__C.EXP_NAME += '_' + str(__C.VAL_INDEX)	

if __C.DATASET == 'GCC':
	__C.EXP_NAME += '_' + __C.VAL_MODE	

__C.EXP_PATH = './exp' # the path of logs, checkpoints, and current codes


#------------------------------VAL------------------------
__C.VAL_DENSE_START = -1
__C.VAL_FREQ = 10 # Before __C.VAL_DENSE_START epoches, the freq is set as __C.VAL_FREQ

#------------------------------VIS------------------------
__C.VISIBLE_NUM_IMGS = 1 #  must be 1 for training images with the different sizes



#================================================================================
#================================================================================
#================================================================================  



===============+++++++++++++++===============

all_ep_1_mae_1062.6_mse_1252.8
    [mae 1062.55 mse 1252.84], [val loss 0.8449]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_2_mae_992.3_mse_1171.6
    [mae 992.32 mse 1171.64], [val loss 0.7753]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_3_mae_884.0_mse_1048.0
    [mae 883.96 mse 1047.98], [val loss 0.6955]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_4_mae_861.4_mse_1016.7
    [mae 861.42 mse 1016.66], [val loss 0.8799]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_5_mae_720.0_mse_854.2
    [mae 719.97 mse 854.23], [val loss 0.7137]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_6_mae_700.3_mse_836.1
    [mae 700.29 mse 836.08], [val loss 0.7884]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_7_mae_549.8_mse_661.3
    [mae 549.78 mse 661.34], [val loss 0.7835]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_9_mae_501.3_mse_601.5
    [mae 501.32 mse 601.51], [val loss 0.6253]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_11_mae_412.6_mse_483.2
    [mae 412.57 mse 483.18], [val loss 0.5455]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_12_mae_395.4_mse_477.5
    [mae 395.40 mse 477.47], [val loss 0.7613]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_13_mae_284.7_mse_339.9
    [mae 284.65 mse 339.89], [val loss 0.5237]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_15_mae_244.2_mse_345.7
    [mae 244.16 mse 345.67], [val loss 0.5626]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_17_mae_295.7_mse_337.2
    [mae 295.69 mse 337.23], [val loss 0.5198]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_18_mae_218.2_mse_290.7
    [mae 218.20 mse 290.72], [val loss 0.5387]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_20_mae_189.1_mse_272.9
    [mae 189.12 mse 272.85], [val loss 0.5229]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_21_mae_162.1_mse_237.9
    [mae 162.12 mse 237.95], [val loss 0.4792]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_27_mae_161.4_mse_236.5
    [mae 161.36 mse 236.54], [val loss 0.4672]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_32_mae_155.1_mse_254.9
    [mae 155.08 mse 254.88], [val loss 0.4495]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_44_mae_180.1_mse_209.4
    [mae 180.09 mse 209.42], [val loss 0.4533]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_47_mae_145.7_mse_234.0
    [mae 145.71 mse 234.05], [val loss 0.4537]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_50_mae_159.1_mse_208.7
    [mae 159.09 mse 208.65], [val loss 0.4448]
===============+++++++++++++++===============

===============+++++++++++++++===============

all_ep_55_mae_136.4_mse_223.6
    [mae 136.40 mse 223.62], [val loss 0.4440]
===============+++++++++++++++===============

